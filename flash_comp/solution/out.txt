Packing solution from source files (override mode)...
Loaded: dsa-topk-ref-v1 (dsa_topk_indexer_fp8_h64_d128_topk2048_ps64)
Entry point: binding.py::kernel
Binding: tvm-ffi
Override mode: using 'dsa_index.py' as binding.py and 'dsa_index.cu' as kernel.cu
Source files packed (3):
  - binding.py
  - dsa_index.py
  - kernel.cu

Running benchmark on Modal B200...

ERROR:
Traceback (most recent call last):
  File "/home/beed/mlsys/venv/lib/python3.12/site-packages/modal/_serialization.py", line 113, in deserialize
    return Unpickler(client, io.BytesIO(s)).load()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'flashinfer_bench'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/beed/mlsys/flash_comp/scripts/run_modal.py", line 628, in _run
    payload = run_benchmark.remote(source_files, solution_meta, None, max_workloads)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/beed/mlsys/venv/lib/python3.12/site-packages/modal/_object.py", line 46, in wrapped
    return await method(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/beed/mlsys/venv/lib/python3.12/site-packages/modal/_functions.py", line 1766, in remote
    return await self._call_function(args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/beed/mlsys/venv/lib/python3.12/site-packages/modal/_functions.py", line 1710, in _call_function
    return await invocation.run_function()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/beed/mlsys/venv/lib/python3.12/site-packages/modal/_functions.py", line 293, in run_function
    return await _process_result(item.result, item.data_format, self.stub, self.client)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/beed/mlsys/venv/lib/python3.12/site-packages/modal/_utils/function_utils.py", line 502, in _process_result
    raise ExecutionError(
modal.exception.ExecutionError: Could not deserialize remote exception due to local error:
Deserialization failed because the 'flashinfer_bench' module is not available in the local environment.
This can happen if your local environment does not have the remote exception definitions.
Here is the remote traceback:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.11/site-packages/flashinfer_bench/bench/runner/persistent_runner.py", line 99, in _start_worker
    raise RunnerFatalError(f"Worker failed to start: {msg}")
flashinfer_bench.bench.runner.runner.RunnerFatalError: Worker failed to start: {'cmd': 'error', 'error': 'Worker startup failed: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/pkg/modal/_runtime/container_io_manager.py", line 947, in handle_input_exception
    yield
  File "/pkg/modal/_container_entrypoint.py", line 172, in run_input_sync
    values = io_context.call_function_sync()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pkg/modal/_runtime/container_io_manager.py", line 225, in call_function_sync
    expected_value_or_values = self.finalized_function.callable(*args, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/run_modal.py", line 201, in run_benchmark
    result_trace_set = Benchmark(bench_trace_set, config).run_all(dump_traces=True)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/flashinfer_bench/bench/benchmark.py", line 52, in __init__
    self._runner = PersistentRunner(self._config.log_dir)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/flashinfer_bench/bench/runner/persistent_runner.py", line 430, in __init__
    self._workers = [PersistentSubprocessWorker(d, log_dir) for d in self._available_devices]
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/flashinfer_bench/bench/runner/persistent_runner.py", line 430, in <listcomp>
    self._workers = [PersistentSubprocessWorker(d, log_dir) for d in self._available_devices]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/flashinfer_bench/bench/runner/persistent_runner.py", line 78, in __init__
    self._start_worker()
  File "/opt/conda/lib/python3.11/site-packages/flashinfer_bench/bench/runner/persistent_runner.py", line 101, in _start_worker
    raise RunnerFatalError(f"Failed to start worker: {e}")
flashinfer_bench.bench.runner.runner.RunnerFatalError: Failed to start worker: Worker failed to start: {'cmd': 'error', 'error': 'Worker startup failed: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination'}
